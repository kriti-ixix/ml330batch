{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8adcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e9522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2323d3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': '/Volumes/Kriti-1/Applications/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/breast_cancer.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e926c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cancer['data'], columns=cancer['feature_names'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc946032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b18a304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = cancer['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a01cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca37b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed98f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea0aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a70c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "635c4ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77c8c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c63fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15764729, 0.08927968, 0.15094608, ..., 0.10975945, 0.14475332,\n",
       "        0.07470812],\n",
       "       [0.6322053 , 0.66351031, 0.65571205, ..., 0.91065292, 0.63160531,\n",
       "        0.45231536],\n",
       "       [0.12728341, 0.60534325, 0.12626263, ..., 0.31364261, 0.16553969,\n",
       "        0.18227732],\n",
       "       ...,\n",
       "       [0.10024977, 0.07642881, 0.09475032, ..., 0.        , 0.38567493,\n",
       "        0.17361931],\n",
       "       [0.07723199, 0.10686507, 0.09652867, ..., 0.35223368, 0.36889557,\n",
       "        0.46018628],\n",
       "       [0.30261031, 0.21981738, 0.28880353, ..., 0.19092784, 0.1995993 ,\n",
       "        0.10553588]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55e5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e29190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\n\\nmodel.add(Dense(units=30, activation='relu'))\\nmodel.add(Dense(units=15, activation='relu'))\\nmodel.add(Dense(units=1, activation='sigmoid'))\\n\\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30, activation='relu'))\n",
    "model.add(Dense(units=15, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa1e3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e3fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelLoss = pd.DataFrame(model.history.history)\n",
    "# modelLoss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42f2d7",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75075d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(units=30, activation='relu'))\n",
    "# model.add(Dense(units=15, activation='relu'))\n",
    "# model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba503713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66a3e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20401b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test), verbose=1, callbacks=[earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef4604ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelLoss = pd.DataFrame(model.history.history)\n",
    "# modelLoss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e6363a",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62df9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=15, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39215292",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "12/12 [==============================] - 4s 32ms/step - loss: 0.7010 - val_loss: 0.6787\n",
      "Epoch 2/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6840 - val_loss: 0.6700\n",
      "Epoch 3/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6667 - val_loss: 0.6623\n",
      "Epoch 4/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6756 - val_loss: 0.6524\n",
      "Epoch 5/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6450 - val_loss: 0.6397\n",
      "Epoch 6/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6406 - val_loss: 0.6257\n",
      "Epoch 7/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6367 - val_loss: 0.6106\n",
      "Epoch 8/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6257 - val_loss: 0.5927\n",
      "Epoch 9/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6081 - val_loss: 0.5717\n",
      "Epoch 10/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5952 - val_loss: 0.5500\n",
      "Epoch 11/600\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5849 - val_loss: 0.5267\n",
      "Epoch 12/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5609 - val_loss: 0.5022\n",
      "Epoch 13/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5458 - val_loss: 0.4780\n",
      "Epoch 14/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5500 - val_loss: 0.4621\n",
      "Epoch 15/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5192 - val_loss: 0.4419\n",
      "Epoch 16/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5133 - val_loss: 0.4201\n",
      "Epoch 17/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4887 - val_loss: 0.3991\n",
      "Epoch 18/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4859 - val_loss: 0.3838\n",
      "Epoch 19/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4697 - val_loss: 0.3660\n",
      "Epoch 20/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4598 - val_loss: 0.3507\n",
      "Epoch 21/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4541 - val_loss: 0.3380\n",
      "Epoch 22/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4149 - val_loss: 0.3245\n",
      "Epoch 23/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4259 - val_loss: 0.3112\n",
      "Epoch 24/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4113 - val_loss: 0.3024\n",
      "Epoch 25/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3752 - val_loss: 0.2883\n",
      "Epoch 26/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3582 - val_loss: 0.2769\n",
      "Epoch 27/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3739 - val_loss: 0.2626\n",
      "Epoch 28/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3497 - val_loss: 0.2548\n",
      "Epoch 29/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3677 - val_loss: 0.2457\n",
      "Epoch 30/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3397 - val_loss: 0.2403\n",
      "Epoch 31/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3175 - val_loss: 0.2308\n",
      "Epoch 32/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2950 - val_loss: 0.2186\n",
      "Epoch 33/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2984 - val_loss: 0.2082\n",
      "Epoch 34/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3017 - val_loss: 0.2021\n",
      "Epoch 35/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2843 - val_loss: 0.1994\n",
      "Epoch 36/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2885 - val_loss: 0.1918\n",
      "Epoch 37/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2990 - val_loss: 0.1889\n",
      "Epoch 38/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2674 - val_loss: 0.1811\n",
      "Epoch 39/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2698 - val_loss: 0.1775\n",
      "Epoch 40/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2462 - val_loss: 0.1713\n",
      "Epoch 41/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2455 - val_loss: 0.1608\n",
      "Epoch 42/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2305 - val_loss: 0.1598\n",
      "Epoch 43/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2487 - val_loss: 0.1629\n",
      "Epoch 44/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2281 - val_loss: 0.1521\n",
      "Epoch 45/600\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2423 - val_loss: 0.1488\n",
      "Epoch 46/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2392 - val_loss: 0.1501\n",
      "Epoch 47/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2176 - val_loss: 0.1442\n",
      "Epoch 48/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2378 - val_loss: 0.1464\n",
      "Epoch 49/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2192 - val_loss: 0.1449\n",
      "Epoch 50/600\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.1978 - val_loss: 0.1457\n",
      "Epoch 51/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2325 - val_loss: 0.1372\n",
      "Epoch 52/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2124 - val_loss: 0.1336\n",
      "Epoch 53/600\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.2115 - val_loss: 0.1304\n",
      "Epoch 54/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2245 - val_loss: 0.1255\n",
      "Epoch 55/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2145 - val_loss: 0.1258\n",
      "Epoch 56/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1695 - val_loss: 0.1233\n",
      "Epoch 57/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1719 - val_loss: 0.1139\n",
      "Epoch 58/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1876 - val_loss: 0.1140\n",
      "Epoch 59/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1754 - val_loss: 0.1135\n",
      "Epoch 60/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1930 - val_loss: 0.1139\n",
      "Epoch 61/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1742 - val_loss: 0.1160\n",
      "Epoch 62/600\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1753 - val_loss: 0.1088\n",
      "Epoch 63/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1880 - val_loss: 0.1044\n",
      "Epoch 64/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1612 - val_loss: 0.1042\n",
      "Epoch 65/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2025 - val_loss: 0.1049\n",
      "Epoch 66/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1783 - val_loss: 0.1004\n",
      "Epoch 67/600\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1727 - val_loss: 0.1107\n",
      "Epoch 68/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1679 - val_loss: 0.1019\n",
      "Epoch 69/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1824 - val_loss: 0.0984\n",
      "Epoch 70/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1621 - val_loss: 0.0957\n",
      "Epoch 71/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1717 - val_loss: 0.0959\n",
      "Epoch 72/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1767 - val_loss: 0.0956\n",
      "Epoch 73/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1593 - val_loss: 0.0938\n",
      "Epoch 74/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1597 - val_loss: 0.0935\n",
      "Epoch 75/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1708 - val_loss: 0.0984\n",
      "Epoch 76/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1467 - val_loss: 0.0893\n",
      "Epoch 77/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1237 - val_loss: 0.0886\n",
      "Epoch 78/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1704 - val_loss: 0.0865\n",
      "Epoch 79/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1372 - val_loss: 0.0889\n",
      "Epoch 80/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1444 - val_loss: 0.0880\n",
      "Epoch 81/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1574 - val_loss: 0.0848\n",
      "Epoch 82/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1625 - val_loss: 0.0848\n",
      "Epoch 83/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1441 - val_loss: 0.0869\n",
      "Epoch 84/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1403 - val_loss: 0.0996\n",
      "Epoch 85/600\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1588 - val_loss: 0.0780\n",
      "Epoch 86/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1451 - val_loss: 0.0753\n",
      "Epoch 87/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1068 - val_loss: 0.0808\n",
      "Epoch 88/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1165 - val_loss: 0.0751\n",
      "Epoch 89/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1404 - val_loss: 0.0737\n",
      "Epoch 90/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1691 - val_loss: 0.0775\n",
      "Epoch 91/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1237 - val_loss: 0.0779\n",
      "Epoch 92/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1172 - val_loss: 0.0810\n",
      "Epoch 93/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1359 - val_loss: 0.0747\n",
      "Epoch 94/600\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1034 - val_loss: 0.0746\n",
      "Epoch 95/600\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1283 - val_loss: 0.0715\n",
      "Epoch 96/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1158 - val_loss: 0.0690\n",
      "Epoch 97/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1345 - val_loss: 0.0807\n",
      "Epoch 98/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1293 - val_loss: 0.0734\n",
      "Epoch 99/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1237 - val_loss: 0.0746\n",
      "Epoch 100/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1493 - val_loss: 0.0801\n",
      "Epoch 101/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1216 - val_loss: 0.0753\n",
      "Epoch 102/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1324 - val_loss: 0.0709\n",
      "Epoch 103/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1238 - val_loss: 0.0702\n",
      "Epoch 104/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1422 - val_loss: 0.0732\n",
      "Epoch 105/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1267 - val_loss: 0.0698\n",
      "Epoch 106/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1404 - val_loss: 0.0733\n",
      "Epoch 107/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1192 - val_loss: 0.0717\n",
      "Epoch 108/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1236 - val_loss: 0.0705\n",
      "Epoch 109/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1146 - val_loss: 0.0696\n",
      "Epoch 110/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1306 - val_loss: 0.0749\n",
      "Epoch 111/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1190 - val_loss: 0.0694\n",
      "Epoch 112/600\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1277 - val_loss: 0.0771\n",
      "Epoch 113/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0909 - val_loss: 0.0687\n",
      "Epoch 114/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1206 - val_loss: 0.0704\n",
      "Epoch 115/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1290 - val_loss: 0.0690\n",
      "Epoch 116/600\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.1257 - val_loss: 0.0710\n",
      "Epoch 117/600\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1201 - val_loss: 0.0710\n",
      "Epoch 118/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1252 - val_loss: 0.0672\n",
      "Epoch 119/600\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1089 - val_loss: 0.0713\n",
      "Epoch 120/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1051 - val_loss: 0.0735\n",
      "Epoch 121/600\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1026 - val_loss: 0.0656\n",
      "Epoch 122/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1091 - val_loss: 0.0675\n",
      "Epoch 123/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1254 - val_loss: 0.0635\n",
      "Epoch 124/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1089 - val_loss: 0.0671\n",
      "Epoch 125/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1242 - val_loss: 0.0794\n",
      "Epoch 126/600\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1090 - val_loss: 0.0698\n",
      "Epoch 127/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0948 - val_loss: 0.0715\n",
      "Epoch 128/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1210 - val_loss: 0.0698\n",
      "Epoch 129/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0999 - val_loss: 0.0653\n",
      "Epoch 130/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0946 - val_loss: 0.0744\n",
      "Epoch 131/600\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1005 - val_loss: 0.0741\n",
      "Epoch 132/600\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.1053 - val_loss: 0.0711\n",
      "Epoch 133/600\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1076 - val_loss: 0.0786\n",
      "Epoch 134/600\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0999 - val_loss: 0.0733\n",
      "Epoch 135/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1101 - val_loss: 0.0698\n",
      "Epoch 136/600\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.1020 - val_loss: 0.0758\n",
      "Epoch 137/600\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1083 - val_loss: 0.0742\n",
      "Epoch 138/600\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0807 - val_loss: 0.0625\n",
      "Epoch 139/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1045 - val_loss: 0.0627\n",
      "Epoch 140/600\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0991 - val_loss: 0.0644\n",
      "Epoch 141/600\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1137 - val_loss: 0.0682\n",
      "Epoch 142/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1009 - val_loss: 0.0738\n",
      "Epoch 143/600\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1082 - val_loss: 0.0697\n",
      "Epoch 144/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1002 - val_loss: 0.0668\n",
      "Epoch 145/600\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0959 - val_loss: 0.0789\n",
      "Epoch 146/600\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.1006 - val_loss: 0.0648\n",
      "Epoch 147/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1074 - val_loss: 0.0657\n",
      "Epoch 148/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1047 - val_loss: 0.0644\n",
      "Epoch 149/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0903 - val_loss: 0.0698\n",
      "Epoch 150/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1101 - val_loss: 0.0678\n",
      "Epoch 151/600\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0905 - val_loss: 0.0743\n",
      "Epoch 152/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1167 - val_loss: 0.0741\n",
      "Epoch 153/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0934 - val_loss: 0.0669\n",
      "Epoch 154/600\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.1098 - val_loss: 0.0687\n",
      "Epoch 155/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0883 - val_loss: 0.0695\n",
      "Epoch 156/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1074 - val_loss: 0.0711\n",
      "Epoch 157/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1110 - val_loss: 0.0634\n",
      "Epoch 158/600\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1042 - val_loss: 0.0621\n",
      "Epoch 159/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0971 - val_loss: 0.0728\n",
      "Epoch 160/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0921 - val_loss: 0.0705\n",
      "Epoch 161/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0802 - val_loss: 0.0681\n",
      "Epoch 162/600\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0926 - val_loss: 0.0672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/600\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0816 - val_loss: 0.0722\n",
      "Epoch 164/600\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0747 - val_loss: 0.0783\n",
      "Epoch 165/600\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0889 - val_loss: 0.0722\n",
      "Epoch 166/600\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0838 - val_loss: 0.0693\n",
      "Epoch 167/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0734 - val_loss: 0.0690\n",
      "Epoch 168/600\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0895 - val_loss: 0.0689\n",
      "Epoch 169/600\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1139 - val_loss: 0.0667\n",
      "Epoch 170/600\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1013 - val_loss: 0.0803\n",
      "Epoch 171/600\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0909 - val_loss: 0.0731\n",
      "Epoch 172/600\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1071 - val_loss: 0.0689\n",
      "Epoch 173/600\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0838 - val_loss: 0.0792\n",
      "Epoch 174/600\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.1055 - val_loss: 0.0848\n",
      "Epoch 175/600\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0869 - val_loss: 0.0763\n",
      "Epoch 176/600\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0866 - val_loss: 0.0767\n",
      "Epoch 177/600\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0903 - val_loss: 0.0759\n",
      "Epoch 178/600\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0957 - val_loss: 0.0712\n",
      "Epoch 00178: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98d9411550>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test), verbose=1, callbacks=[earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1409916b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelLoss = pd.DataFrame(model.history.history)\n",
    "modelLoss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f7efd",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9933606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Kriti-1/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4af03dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fa7d2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98        62\n",
      "           1       0.98      0.99      0.99       126\n",
      "\n",
      "    accuracy                           0.98       188\n",
      "   macro avg       0.98      0.98      0.98       188\n",
      "weighted avg       0.98      0.98      0.98       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1156b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
